apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    calicoCNIAddon: enabled
    cluster.x-k8s.io/cluster-name: testlab
    metricsServerAddon: enabled
  name: testlab
  namespace: testlab
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 10.162.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: testlab-control-plane
    namespace: testlab
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
    kind: ProxmoxCluster
    name: testlab
    namespace: testlab
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: ProxmoxCluster
metadata:
  name: testlab
  namespace: testlab
spec:
  allowedNodes:
  - pve1
  - pve2
  - pve3
  controlPlaneEndpoint:
    host: 10.202.70.2
    port: 6443
  dnsServers:
  - 10.202.70.1
  - 1.1.1.1
  - 1.1.0.0
  ipv4Config:
    addresses:
    - 10.202.70.10-10.202.70.30
    gateway: 10.202.70.1
    prefix: 24
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: testlab-control-plane
  namespace: testlab
spec:
  kubeadmConfigSpec:
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          creationTimestamp: null
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
          - args:
            - manager
            env:
            - name: cp_enable
              value: "true"
            - name: vip_interface
              value: ""
            - name: address
              value: 10.202.70.2
            - name: port
              value: "6443"
            - name: vip_arp
              value: "true"
            - name: vip_leaderelection
              value: "true"
            - name: vip_leaseduration
              value: "15"
            - name: vip_renewdeadline
              value: "10"
            - name: vip_retryperiod
              value: "2"
            image: ghcr.io/kube-vip/kube-vip:v0.7.1
            imagePullPolicy: IfNotPresent
            name: kube-vip
            resources: {}
            securityContext:
              capabilities:
                add:
                - NET_ADMIN
                - NET_RAW
            volumeMounts:
            - mountPath: /etc/kubernetes/admin.conf
              name: kubeconfig
          hostAliases:
          - hostnames:
            - localhost
            - kubernetes
            ip: 127.0.0.1
          hostNetwork: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/admin.conf
              type: FileOrCreate
            name: kubeconfig
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
    - content: |
        #!/bin/bash

        # Copyright 2020 The Kubernetes Authors.
        #
        # Licensed under the Apache License, Version 2.0 (the "License");
        # you may not use this file except in compliance with the License.
        # You may obtain a copy of the License at
        #
        #     http://www.apache.org/licenses/LICENSE-2.0
        #
        # Unless required by applicable law or agreed to in writing, software
        # distributed under the License is distributed on an "AS IS" BASIS,
        # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
        # See the License for the specific language governing permissions and
        # limitations under the License.

        set -e

        # Configure the workaround required for kubeadm init with kube-vip:
        # xref: https://github.com/kube-vip/kube-vip/issues/684

        # Nothing to do for kubernetes < v1.29
        KUBEADM_MINOR="$(kubeadm version -o short | cut -d '.' -f 2)"
        if [[ "$KUBEADM_MINOR" -lt "29" ]]; then
          exit 0
        fi

        IS_KUBEADM_INIT="false"

        # cloud-init kubeadm init
        if [[ -f /run/kubeadm/kubeadm.yaml ]]; then
          IS_KUBEADM_INIT="true"
        fi

        # ignition kubeadm init
        if [[ -f /etc/kubeadm.sh ]] && grep -q -e "kubeadm init" /etc/kubeadm.sh; then
          IS_KUBEADM_INIT="true"
        fi

        if [[ "$IS_KUBEADM_INIT" == "true" ]]; then
          sed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' \
            /etc/kubernetes/manifests/kube-vip.yaml
        fi
      owner: root:root
      path: /etc/kube-vip-prepare.sh
      permissions: "0700"
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          provider-id: proxmox://'{{ ds.meta_data.instance_id }}'
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          provider-id: proxmox://'{{ ds.meta_data.instance_id }}'
    preKubeadmCommands:
    - /etc/kube-vip-prepare.sh
    users:
    - name: root
      sshAuthorizedKeys:
      - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHfEW8qJ0eNOKkGMctVW35LXYhfNme7+zOujaF+KEL82
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
      kind: ProxmoxMachineTemplate
      name: testlab-control-plane
      namespace: testlab
  replicas: 1
  version: v1.32.4
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: ProxmoxMachineTemplate
metadata:
  name: testlab-control-plane
  namespace: testlab
spec:
  template:
    spec:
      disks:
        bootVolume:
          disk: scsi0
          sizeGb: 64
      format: qcow2
      full: true
      memoryMiB: 8192
      network:
        default:
          bridge: kubetest
          model: virtio
      numCores: 4
      numSockets: 1
      sourceNode: pve1
      templateID: 900
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: testlab
  name: testlab-workers
  namespace: testlab
spec:
  clusterName: testlab
  replicas: 1
  selector:
    matchLabels: null
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: testlab
        node-role.kubernetes.io/node: ""
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: testlab-worker
          namespace: testlab
      clusterName: testlab
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
        kind: ProxmoxMachineTemplate
        name: testlab-worker
        namespace: testlab
      version: v1.32.4
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: ProxmoxMachineTemplate
metadata:
  name: testlab-worker
  namespace: testlab
spec:
  template:
    spec:
      disks:
        bootVolume:
          disk: scsi0
          sizeGb: 64
      format: qcow2
      full: true
      memoryMiB: 32768
      network:
        default:
          bridge: kubetest
          model: virtio
      numCores: 8
      numSockets: 1
      sourceNode: pve1
      templateID: 900
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: testlab-worker
  namespace: testlab
spec:
  template:
    spec:
      clusterConfiguration:
        apiServer:
          certSANs:
          - testlab.local.zachary.day
          extraArgs:
            service-account-key-file: /etc/kubernetes/pki/sa-custom.pub
            service-account-signing-key-file: /etc/kubernetes/pki/sa-custom.key
      files:
      - append: false
        contentFrom:
          secret:
            key: sa.key
            name: service-account-signing-key
        owner: root:root
        path: /etc/kubernetes/pki/sa-custom.key
      - append: false
        contentFrom:
          secret:
            key: sa.pub
            name: service-account-signing-key
        owner: root:root
        path: /etc/kubernetes/pki/sa-custom.pub
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            provider-id: proxmox://'{{ ds.meta_data.instance_id }}'
      users:
      - name: root
        sshAuthorizedKeys:
        - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHfEW8qJ0eNOKkGMctVW35LXYhfNme7+zOujaF+KEL82
